{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define file names and their reasoning status\n",
        "file_configs = {\n",
        "    \"generated_Few_Shot_DeepMental_responses.csv\": True,   # Has <think>\n",
        "    \"generated_Fine_Tune_DeepMental_responses.csv\": True,  # Has <think>\n",
        "    \"generated_Fine_Tune_Traditional_responses.csv\": False  # No <think>\n",
        "}\n",
        "\n",
        "# Initialize empty list for combined data\n",
        "combined_data = []\n",
        "\n",
        "# Function to extract response after \"### Response:\"\n",
        "def extract_response(text):\n",
        "    match = re.search(r\"### Response:\\s*(.*)\", text, re.DOTALL)\n",
        "    return match.group(1).strip() if match else text.strip()\n",
        "\n",
        "# Function to remove <think>...</think>\n",
        "def remove_think_tags(text):\n",
        "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
        "\n",
        "# Process each file\n",
        "for file, has_think in file_configs.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        \n",
        "        # Extract response text\n",
        "        df[\"clean_response\"] = df[\"response\"].apply(extract_response)\n",
        "        \n",
        "        if has_think:\n",
        "            # Remove <think> for the no-reasoning version\n",
        "            df[\"response_without_think\"] = df[\"clean_response\"].apply(remove_think_tags)\n",
        "        else:\n",
        "            # If the file does not contain <think>, keep responses the same\n",
        "            df[\"response_without_think\"] = df[\"clean_response\"]\n",
        "        \n",
        "        # Add a column to track which model generated the response\n",
        "        df[\"model\"] = file.replace(\".csv\", \"\")  # Use filename as model identifier\n",
        "\n",
        "        # Append data to combined list\n",
        "        combined_data.extend(df[[\"instruction\", \"input\", \"clean_response\", \"response_without_think\", \"model\"]].values.tolist())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Warning: File {file} not found. Skipping.\")\n",
        "\n",
        "# Create a single DataFrame with all responses\n",
        "df_combined = pd.DataFrame(combined_data, columns=[\"instruction\", \"input\", \"response_with_think\", \"response_without_think\", \"model\"])\n",
        "\n",
        "# Save the final combined file\n",
        "df_combined.to_csv(\"final_combined_responses.csv\", index=False)\n",
        "\n",
        "print(\"✅ Final combined response file saved as 'final_combined_responses.csv'!\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from Hugging Face\n",
        "DATASET_ID = \"ShenLab/MentalChat16K\"\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")  # Assuming 'train' split\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_expected = pd.DataFrame(dataset)\n",
        "\n",
        "# Select relevant columns: Assuming 'input' and 'response' are the correct column names\n",
        "if \"input\" in df_expected.columns and \"response\" in df_expected.columns:\n",
        "    df_expected = df_expected[[\"input\", \"response\"]]  # 'response' is considered the expected output\n",
        "else:\n",
        "    print(\"⚠️ Warning: Column names might be different in the dataset. Check and update accordingly.\")\n",
        "\n",
        "# Save expected responses\n",
        "csv_filename = \"expected_responses.csv\"\n",
        "df_expected.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"✅ Expected responses file saved as '{csv_filename}'!\")\n",
        "\n",
        "# Display a sample of expected responses\n",
        "print(df_expected.head())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "⚠️ Warning: Column names might be different in the dataset. Check and update accordingly.\n✅ Expected responses file saved as 'expected_responses.csv'!\n                                         instruction  \\\n0  You are a helpful mental health counselling as...   \n1  You are a helpful mental health counselling as...   \n2  You are a helpful mental health counselling as...   \n3  You are a helpful mental health counselling as...   \n4  You are a helpful mental health counselling as...   \n\n                                               input  \\\n0  I've been struggling with my mental health for...   \n1  I've been feeling overwhelmed with my caregivi...   \n2  I've been feeling constantly anxious and unabl...   \n3  My mom has Alzheimer's, and I've been her prim...   \n4  I've tried setting boundaries, but it feels li...   \n\n                                              output  \n0  I understand that you've been dealing with a s...  \n1  Your situation is complex, and it's important ...  \n2  I can see that you're dealing with a great dea...  \n3  I'm sorry to hear that your siblings' demands ...  \n4  Your concerns are valid, and it's crucial to p...  \n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1740672426715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "expected_responses_file = \"expected_responses.csv\"\n",
        "generated_responses_file = \"final_combined_responses.csv\"\n",
        "\n",
        "# Load the expected responses file\n",
        "df_expected = pd.read_csv(expected_responses_file)\n",
        "\n",
        "# Load the generated responses file\n",
        "df_generated = pd.read_csv(generated_responses_file)\n",
        "\n",
        "# Ensure only one match per input by removing duplicates from df_expected\n",
        "df_expected = df_expected.drop_duplicates(subset=[\"input\"])\n",
        "\n",
        "# Merge the expected responses with generated responses based on 'input'\n",
        "df_merged = df_generated.merge(df_expected[[\"input\", \"output\"]], on=\"input\", how=\"left\")\n",
        "\n",
        "# Rename the expected response column for clarity\n",
        "df_merged.rename(columns={\"response\": \"expected_response\"}, inplace=True)\n",
        "\n",
        "# Save the final file with expected responses included\n",
        "df_merged.to_csv(\"final_combined_responses_with_expected.csv\", index=False)\n",
        "\n",
        "# Display the final merged DataFrame\n",
        "\n",
        "\n",
        "print(\"✅ Final file with expected responses saved as 'final_combined_responses_with_expected.csv'!\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Final file with expected responses saved as 'final_combined_responses_with_expected.csv'!\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1740672805855
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}